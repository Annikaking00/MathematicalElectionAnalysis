{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election, grid)\n",
    "from gerrychain.metrics import mean_median, partisan_bias, polsby_popper, efficiency_gap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import inspect\n",
    "import pickle\n",
    "import geopandas as gp\n",
    "from shapely.geometry import LineString, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools file\n",
    "from merges import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts = gp.read_file(\"UtahData/new_shp.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The precincts file in the cell above is essentially equivalent to \n",
    "precincts_old = gp.read_file('UtahData/2018_precincts_w_votes_and_pop.shp')\n",
    "\n",
    "# with the following changes made\n",
    "precincts_old.loc[101, 'geometry'] = precincts_old.loc[101, 'geometry'][0]\n",
    "precincts_old.loc[175, 'geometry'] = precincts_old.loc[175, 'geometry'][0]\n",
    "# (deleting small islands)\n",
    "precincts_old.loc[1887, 'US_Distric'] = 1\n",
    "# (changing the district of a precinct in Summit County to reflect the fact that all of Summit County is in district 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graph data\n",
    "utah = Graph.from_json(\"UtahData/graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph in the cell above is essentially equivalent to \n",
    "graph_old = Graph.from_json('UtahData/2018_full_with_clean_buffer_graph.json')\n",
    "\n",
    "# with the following change made:\n",
    "graph_old.nodes[1887]['US_Distric'] = 1\n",
    "# (changing the district of a precinct in Summit County to reflect the fact that all of Summit County is in district 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the graph and gdf we are working with\n",
    "graph, gdf = utah.copy(), precincts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put precinct 1887 (population zero) into district 1.\n",
    "# (I believe this is an error because several online sources list that all of Summit County is in district 1.)\n",
    "graph.nodes[1887]['US_Distric'] = 1\n",
    "gdf.loc[1887, 'US_Distric'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SEN_REP', 'SEN_DEM', 'G_DEM', 'G_REP']\n",
    "for column in columns:\n",
    "    s = np.nonzero(gdf[column].isnull().values)\n",
    "    for i in s[0]:\n",
    "        gdf.iloc[i, gdf.columns.get_loc(column)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete small sliver\n",
    "gdf.loc[40,'geometry'] = precincts.loc[40,'geometry'][0]\n",
    "\n",
    "# Delete small sliver\n",
    "gdf.loc[229, 'geometry'] = precincts.loc[229, 'geometry'][0]\n",
    "\n",
    "# Delete small island\n",
    "gdf.loc[543,'geometry'] = precincts.loc[543,'geometry'][0]\n",
    "\n",
    "# Delete several small slivers\n",
    "gdf.loc[636,'geometry'] = precincts.loc[636, 'geometry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 19, 90, 107, 109, 112, 118, 128, 130, 131, 137, 139, 140, 141, 142, 146, 150, 152, 156, 161, 211, 235, 238, 239, 242, 248, 249, 262, 281, 315, 317, 318, 319, 321, 322, 323, 330, 331, 341, 343, 363, 395, 444, 515, 525, 532, 556, 557, 569, 599, 602, 604, 607, 610, 613, 615, 624, 629, 630, 634, 638, 646, 661, 670, 688, 719, 722, 749, 844, 957, 981, 1004, 1012, 1013, 1014, 1016, 1021, 1051, 1121, 1131, 1138, 1139, 1145, 1151, 1164, 1165, 1171, 1220, 1224, 1229, 1230, 1242, 1256, 1258, 1280, 1294, 1295, 1307, 1308, 1315, 1319, 1320, 1345, 1353, 1357, 1360, 1361, 1369, 1372, 1375, 1393, 1406, 1414, 1419, 1423, 1430, 1467, 1502, 1510, 1515, 1516, 1518, 1523, 1530, 1531, 1548, 1570, 1571, 1577, 1600, 1604, 1605, 1606, 1607, 1608, 1611, 1612, 1613, 1614, 1615, 1616, 1619, 1623, 1638, 1645, 1646, 1650, 1667, 1688, 1692, 1714, 1715, 1716, 1729, 1731, 1739, 1744, 1749, 1759, 1760, 1763, 1765, 1769, 1770, 1783, 1798, 1808, 1810, 1812, 1816, 1821, 1822, 1824, 1825, 1828, 1830, 1887, 1929, 1995, 1997, 2023, 2026, 2029, 2034, 2037, 2045, 2052, 2066, 2067, 2078, 2079, 2103, 2107, 2108, 2121, 2146, 2164, 2191, 2279, 2290, 2295, 2300, 2301, 2365, 2388, 2413, 2459, 2461, 2468, 2487, 2504, 2509, 2532, 2546, 2606, 2622, 2634, 2641, 2664, 2665, 2684, 2726, 2735, 2754, 2761, 2766, 2793, 2802, 2833, 2850, 2854, 2856, 2864, 2885, 2895, 2896, 2898, 2901, 2906, 2907, 2928, 2930, 2944, 2957, 2967, 2971]\n"
     ]
    }
   ],
   "source": [
    "# Find the multipolygons\n",
    "multipolygons = []\n",
    "for i, poly in enumerate(gdf['geometry']):\n",
    "    if type(poly) != Polygon:\n",
    "        multipolygons.append(i)\n",
    "print(multipolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n",
      "1744\n",
      "2164\n",
      "2468\n",
      "2532\n",
      "2664\n",
      "2885\n",
      "2906\n",
      "2957\n"
     ]
    }
   ],
   "source": [
    "# Delete very small islands\n",
    "\n",
    "# necessary to amend 2164, 2468, 2664\n",
    "# 1423, 1744, 2532, 2885, 2906, 2957 also included \n",
    "\n",
    "tol = 1 # square meter \n",
    "for mp in multipolygons:\n",
    "    multip = gdf.iloc[mp]['geometry']\n",
    "    if sum(poly.area for poly in multip[1:]) < tol:\n",
    "        print(mp)\n",
    "        gdf.loc[mp, 'geometry'] = gdf.loc[mp, 'geometry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some common parameters for merging\n",
    "columns_to_keep = ['geometry', ('CountyID', 'first'), ('VistaID', 'sum'), ('POP100', 'sum'), \n",
    "                                 ('SEN_DEM', 'sum'), ('SEN_REP', 'sum'), ('G_DEM', 'sum'), ('G_REP', 'sum'),\n",
    "                                 ('US_Distric', 'first'), ('UT_SEN','first'), ('UT_HOUSE','first')]\n",
    "\n",
    "column_labels = ['geometry', 'CountyID', 'VistaID', 'POP100', 'SEN_DEM', 'SEN_REP', 'G_DEM',\n",
    "                                 'G_REP' , 'US_Distric', 'UT_SEN', 'UT_HOUSE']\n",
    "\n",
    "attributes_to_sum = ['POP100', 'area', 'SHAPE_Area', 'SEN_DEM', 'SEN_REP', 'G_DEM', 'G_REP']\n",
    "\n",
    "attributes_to_join = ['VistaID', 'PrecinctID', 'SubPrecinc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-39015e928524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Perform the merge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgdf_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_dissolve_gdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdissolve_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_keep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mgraph_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_dissolve_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdissolve_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes_to_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes_to_join\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\UtahElections\\JacobSandbox\\merges.py\u001b[0m in \u001b[0;36mperform_dissolve_gdf\u001b[1;34m(precincts, dissolve, columns_to_keep, new_column_names)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_to_keep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_column_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mmerged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3908\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3909\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index does not support mutable operations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "# These precincts have to be merged\n",
    "merge_init = Merge(len(graph))\n",
    "merge_init.add(set([2957, 2967]))\n",
    "dissolve_init = merge_init.get_dissolve()\n",
    "\n",
    "# Perform the merge\n",
    "gdf_init = perform_dissolve_gdf(gdf, dissolve_init, columns_to_keep, column_labels)\n",
    "graph_init = perform_dissolve_graph(graph, dissolve_init, attributes_to_sum, attributes_to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete two small islands\n",
    "s = gdf_init.loc[2957, 'geometry']\n",
    "i = np.argmax([s[i].area for i in range(len(s))])\n",
    "gdf_init.loc[2957, 'geometry'] = gdf_init.loc[2957, 'geometry'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_init.loc[2957, 'geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Merging Multipolygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the precincts geometries are either a shapely Polygon or a list of shapely Polygons, called a Multipolygon. A Polygon may not be simply connected (i. e. it may have holes) but it will be connected. For Multipolygons we have no such guarantee, and in fact we have reason to suspect that they are disconnected (otherwise they could be cast into a Polygon). To make sure that our Markov chain does not generate disconnected districts, we must ensure that each of the underlying precincts are connected. We can do this by finding all of the precincts which are of type Multipolygon, and then merging them with one of their neighbors. In my code, this choice is made by determining which of the neighbors in the same county and congressional district has the largest shared perimeter with a given district, and then merging that polygon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the graph we operate on \n",
    "graph, gdf = graph_init, gdf_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the multipolygons\n",
    "multipolygons = []\n",
    "for i, poly in enumerate(gdf['geometry']):\n",
    "    if type(poly) != Polygon:\n",
    "        multipolygons.append(i)\n",
    "print(multipolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the multipolygons\n",
    "f = gdf.copy()\n",
    "mp = np.array([1 if i in multipolygons else 0 for i in range(len(f))])\n",
    "f['mp'] = mp\n",
    "\n",
    "# Plot the multipolygons\n",
    "size, dpi =(14,7), 300\n",
    "fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "f.plot(column='mp', ax=ax, cmap='Spectral')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Legend: Red: Polygon, Blue: Multipolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# time to run: approx 1 min. Gets stuck at 171 for a little, but don't worry\n",
    "merge_mp = merge_multipolygons(graph, gdf, preserve_ut_house=True)\n",
    "dissolve_mp = merge_mp.get_dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(dissolve_mp == dissolve_mp[1825])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the multipolygons along with the nodes they will be merged with\n",
    "f = gdf.copy()\n",
    "s = set([subpart for part in merge_mp.merges for subpart in part])\n",
    "mps_and_neighbors = np.array([1 if (n in s) else 0 for n in range(len(f)) ])\n",
    "\n",
    "f['mp'] = 0.5*(mp + mps_and_neighbors)\n",
    "\n",
    "# Plot the zero-population nodes\n",
    "size, dpi = (14,7), 300\n",
    "fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "f.plot(column='mp', ax=ax, cmap='Spectral')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Legend: Red: Polygon, Blue: Multipolygon, Yellow: Neighboring precinct selected to be merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_mp2 = merge_init * merge_mp\n",
    "dissolve_mp2 = merge_mp2.get_dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge\n",
    "gdf_mp = perform_dissolve_gdf(gdf_init, dissolve_mp, columns_to_keep, column_labels)\n",
    "graph_mp = perform_dissolve_graph(graph_init, dissolve_mp, attributes_to_sum, attributes_to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decreased by\n",
    "len(graph_mp) - len(graph_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "f = gdf_mp.copy()\n",
    "f['mp'] = np.array([1 if i in dissolve_mp[multipolygons] else 0 for i in range(len(f))])\n",
    "\n",
    "# Plot the multipolygons\n",
    "size, dpi =(14,7), 300\n",
    "fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "f.plot(column='mp', ax=ax, cmap='Spectral')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Legend: Red: Polygon, Blue: Merged Multipolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: One Neighbor Precincts and Separating Precincts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One essential motivation for merging precincts is to streamline the process of using Monte Carlo Markov Chain models via the flip proposal. The flip proposal is the transition between states in our Markov chain. It selects a precinct on one of the cut edges of the graph, and then changes its district assignment to the adjacent district. This transition forms a reversible Markov Chain. By simulating thousands of these flips, we hope to explore the sample space of possible districting plans. However, the flip proposal has some limitations. In particular, if precint A is contained inside precinct B (and thus has no other neighboring precincts) and precinct B is selected to be flipped, when the new districting assignment is generated, B's old district will be left discontiguous and thus invalid, because A will be a disconnected precinct in the old district. The algorithm will reject the new proposed plan due to its invalidity. Therefore, the precinct B (and precinct A) can never be flipped into a different district, and the Markov chain will not explore the whole sample space, and may be confined to a particular region of the sample space. Of course, the solution is that A and B can be flipped if they are flipped together. The simplest way to proceed is to use the normal flipping algorithm, but after having merged precincts A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the graph we operate on \n",
    "graph, gdf = graph_mp, gdf_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the separating precincts, approx 5 min\n",
    "ids2, neighbor_ids2, separators, merge_sp = get_separators(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that donut precincts are in the same senate and house districts as the precincts they contain\n",
    "for part in merge_sp.merges:\n",
    "    part = list(part)\n",
    "    cong, sen, house = utah.nodes[part[0]]['US_Distric'], utah.nodes[part[0]]['UT_SEN'], utah.nodes[part[0]]['UT_HOUSE']\n",
    "    \n",
    "    for precinct in part:\n",
    "        cong1, sen1, house1 = utah.nodes[precinct]['US_Distric'], utah.nodes[part[0]]['UT_SEN'], utah.nodes[precinct]['UT_HOUSE']\n",
    "    \n",
    "        if (cong1 != cong) or (sen1 != sen) or (house1 != house):\n",
    "            print(precinct)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the one-neighbor nodes\n",
    "f = gdf.copy()\n",
    "f[\"one neighbor\"] = np.array([1 if (i in ids2 or i in neighbor_ids2) else 0 for i in range(len(f))])\n",
    "\n",
    "# Plot the one neighbor precincts with their one neighbor\n",
    "size, dpi =(3,2), 300\n",
    "fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "f.plot(column='one neighbor', ax=ax, cmap='Spectral')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Legend: Red: Normal Precinct, Blue: Separating precinct, or precinct contained in it\n",
    "\n",
    "# plt.savefig(\"isolated_precincts2.png\", dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "# Look at Sanpete County!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolve_sp = merge_sp.get_dissolve()\n",
    "\n",
    "# Merge so that the new merged precincts are flippable\n",
    "gdf_mp_sp = perform_dissolve_gdf(gdf_mp, dissolve_sp, columns_to_keep, column_labels)\n",
    "graph_mp_sp = perform_dissolve_graph(graph_mp, dissolve_sp, attributes_to_sum, attributes_to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_mp_sp = merge_mp2 * merge_sp\n",
    "dissolve_mp_sp = merge_mp_sp.get_dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the merged precincts\n",
    "f = gdf_mp_sp.copy()\n",
    "f[\"one neighbor\"] = np.array([1 if (n in dissolve_sp[ids2] or n in dissolve_sp[neighbor_ids2]) else 0 for n in range(len(f))])\n",
    "\n",
    "# Plot the one neighbor precincts with their one neighbor\n",
    "size, dpi =(3,2), 300\n",
    "fig, ax = plt.subplots(figsize=size, dpi=dpi)\n",
    "f.plot(column='one neighbor', ax=ax, cmap='Spectral')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Legend: Red: Normal Precinct, Blue: Separating precinct, or precinct contained in it (Merged)\n",
    "# plt.savefig(\"isolated_precincts_merged1.png\", dpi=dpi, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decreased by\n",
    "len(graph_mp) - len(graph_mp_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No multipolygons\n",
    "all(type(poly) == Polygon for poly in gdf_mp_sp['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No separating precincts (approx 5 min to run)\n",
    "separate = []\n",
    "for node in graph_mp_sp:\n",
    "    copy = graph_mp_sp.copy()\n",
    "    copy.remove_node(node)\n",
    "    separate.append(nx.is_connected(copy))\n",
    "all(separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the total population stayed the same\n",
    "sum(graph_mp_sp.nodes[n]['POP100'] for n in graph_mp_sp.nodes) == sum(utah.nodes[n]['POP100'] for n in utah.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_mp_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can package these files up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp_sp.to_file(\"gdf_mp_sp.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graph_mp_sp, open(\"graph_mp_sp.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Check to see which cut edges are \"unflippable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with isolated precincts removed\n",
    "plot_graph(gdf_mp_sp, graph_mp_sp, dpi=400, size=7, save=False, savetitle='graph_after_merging1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
